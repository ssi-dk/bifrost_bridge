{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |default_exp rmlst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "# See above? this hides these blocks, meaning these blocks aren't in the module and aren't in the documentation\n",
    "import nbdev\n",
    "from nbdev.showdoc import *  # ignore this Pylance warning in favor of following nbdev docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "# That export there, it makes sure this code goes into the module.\n",
    "\n",
    "# standard libs\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Common to template\n",
    "# add into settings.ini, requirements, package name is python-dotenv, for conda build ensure `conda config --add channels conda-forge`\n",
    "import dotenv  # for loading config from .env files, https://pypi.org/project/python-dotenv/\n",
    "import envyaml  # Allows to loads env vars into a yaml file, https://github.com/thesimj/envyaml\n",
    "import fastcore  # To add functionality related to nbdev development, https://github.com/fastai/fastcore/\n",
    "from fastcore import (\n",
    "    test,\n",
    ")\n",
    "from fastcore.script import (\n",
    "    call_parse,\n",
    ")  # for @call_parse, https://fastcore.fast.ai/script\n",
    "import json  # for nicely printing json and yaml\n",
    "from fastcore import test\n",
    "from bifrost_bridge import core\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the notebooks now are located in the `nbs` folder, we need to change the python `wd` for the notebook to the project folder. Keep this included in all notebooks but don't export it to the package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block should never be exported. It is to have python running in the project (and not the nbs) dir, and to initiate the package using pip.\n",
    "os.chdir(core.PROJECT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##################################################CODE_SEGMENT###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "def process_rmlst_data(\n",
    "    input_path:str,\n",
    "    output_path:str = './output.tsv',\n",
    "    replace_header:str = None,\n",
    "    filter_columns:str = None,\n",
    "    add_header:str = None):\n",
    "\n",
    "    \"\"\"\n",
    "    Command-line interface for processing rmlst data.\n",
    "\n",
    "    This function sets up an argument parser to handle command-line arguments for processing rmlst data files.\n",
    "    It supports specifying input and output file paths, replacing headers, filtering columns, and handling the presence or absence of headers in the input file.\n",
    "\n",
    "    Arguments:\n",
    "        input_path (str): Path to the input file.\n",
    "        output_path (str): Path to the output file (default: './output.tsv').\n",
    "        replace_header (str): Header to replace the existing header (default: None).\n",
    "        filter_columns (str): Columns to filter from the header (default: None).\n",
    "        header_exists (int): Indicates if the header exists in the input file (default: 1).\n",
    "        add_header (str): Header to add if the header does not exist in the input file (default: None).\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    df = core.DataFrame()\n",
    "\n",
    "    if not os.path.exists(input_path):\n",
    "        raise FileNotFoundError(f\"The input file {input_path} does not exist.\")\n",
    "    if os.stat(input_path).st_size > 0:\n",
    "        #df.import_data(input_path, file_type='tsv', add_header=add_header)\n",
    "        with open(input_path) as rmlst_json:\n",
    "            rmlst_dict = json.load(rmlst_json)\n",
    "        rmlst_dict.pop('exact_matches') # remove the big section with data per contig\n",
    "        taxon_prediction_df = pd.json_normalize(rmlst_dict['taxon_prediction']) # this dict is a list and may contain several entries\n",
    "        #print(taxon_prediction_df)\n",
    "        def concatenate_vector(vector: list, sep=',') -> str:\n",
    "            return ','.join([str(i) for i in vector])\n",
    "\n",
    "        taxon_prediction_df = taxon_prediction_df.apply(concatenate_vector, axis=0).to_frame().T # concatenate the list into one line\n",
    "        #print(rmlst_dict['taxon_prediction'])\n",
    "        #fields_df = pd.Series(rmlst_dict['fields']).to_frame().T # some samples don't get this object, skip it\n",
    "        # TODO: concatenate df, put it in to the scuffed povilas object and then carry on\n",
    "        #print(fields_df)\n",
    "        #print(taxon_prediction_df)\n",
    "        #conc_df = pd.concat((fields_df, taxon_prediction_df), axis=1)\n",
    "        conc_df = taxon_prediction_df \n",
    "        df.df = conc_df\n",
    "\n",
    "        if filter_columns:\n",
    "            df.filter_columns(filter_columns)\n",
    "\n",
    "        if replace_header:\n",
    "            df.rename_header(replace_header)\n",
    "        \n",
    "        #df.show()\n",
    "\n",
    "        df.export_data(output_path, file_type='tsv')\n",
    "    else:\n",
    "        empty_df = pd.DataFrame(columns = [col.strip() for col in replace_header.split(',')])\n",
    "        empty_df.to_csv(output_path, index=False)\n",
    "\n",
    "@call_parse\n",
    "def process_rmlst_data_from_cli(\n",
    "    input_path:str,\n",
    "    output_path:str = './output.tsv',\n",
    "    replace_header:str = None,\n",
    "    filter_columns:str = None,\n",
    "    add_header:str = None):\n",
    "    process_rmlst_data(input_path, output_path, replace_header, filter_columns, add_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#Example usage of the function\n",
    "process_rmlst_data(\n",
    "  input_path='test_data/rmlst.json', \n",
    "  output_path='test_data/rmlst_testout.tsv'#,\n",
    "   #filter_columns=\"Query / Template length\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#Example usage of the function\n",
    "process_rmlst_data(\n",
    "  input_path='test_data/rmlst.json', \n",
    "  output_path='test_data/rmlst_testout_custom_header.tsv',\n",
    "  filter_columns=\"taxon,taxonomy,rank,support\",\n",
    "  replace_header=\"match,taxonomy,rank,percentage\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Database Plasmid Identity Query / Template length Contig Position in contig  \\\n",
      "0                                                                               \n",
      "\n",
      "  Note Accession number  \n",
      "0                        \n"
     ]
    }
   ],
   "source": [
    "#|hide\n",
    "#Example usage of the function\n",
    "#process_rmlst_data(\n",
    "#   input_path='test_data/rmlst_empty.tsv', \n",
    "#   output_path='test_data/rmlst_empty_testout.tsv',\n",
    "#   filter_columns=\"Query / Template length\"\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##################################################CODE_SEGMENT###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# This is included at the end to ensure when you run through your notebook the code is also transferred to the associated python package\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
