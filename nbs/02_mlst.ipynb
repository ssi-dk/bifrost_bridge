{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |default_exp mlst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "# See above? this hides these blocks, meaning these blocks aren't in the module and aren't in the documentation\n",
    "import nbdev\n",
    "from nbdev.showdoc import *  # ignore this Pylance warning in favor of following nbdev docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "# That export there, it makes sure this code goes into the module.\n",
    "\n",
    "# standard libs\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Common to template\n",
    "# add into settings.ini, requirements, package name is python-dotenv, for conda build ensure `conda config --add channels conda-forge`\n",
    "import dotenv  # for loading config from .env files, https://pypi.org/project/python-dotenv/\n",
    "import envyaml  # Allows to loads env vars into a yaml file, https://github.com/thesimj/envyaml\n",
    "import fastcore  # To add functionality related to nbdev development, https://github.com/fastai/fastcore/\n",
    "from fastcore import (\n",
    "    test,\n",
    ")\n",
    "from fastcore.script import (\n",
    "    call_parse,\n",
    ")  # for @call_parse, https://fastcore.fast.ai/script\n",
    "import json  # for nicely printing json and yaml\n",
    "from fastcore import test\n",
    "from bifrost_bridge import core\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the notebooks now are located in the `nbs` folder, we need to change the python `wd` for the notebook to the project folder. Keep this included in all notebooks but don't export it to the package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block should never be exported. It is to have python running in the project (and not the nbs) dir, and to initiate the package using pip.\n",
    "os.chdir(core.PROJECT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##################################################CODE_SEGMENT###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "def process_mlst_data(\n",
    "    input_path:str,\n",
    "    output_path:str = './output.tsv',\n",
    "    add_header:str = None,\n",
    "    replace_header:str = None,\n",
    "    filter_columns:str = None,\n",
    "    remove_sampleid:bool = False,\n",
    "    combine_alleles:bool = False):\n",
    "\n",
    "    \"\"\"\n",
    "    Command-line interface for processing MLST data.\n",
    "\n",
    "    This function sets up an argument parser to handle command-line arguments for processing MLST data files.\n",
    "    It supports specifying input and output file paths, replacing headers, filtering columns, and handling the presence or absence of headers in the input file.\n",
    "\n",
    "    Arguments:\n",
    "        input_path (str): Path to the input file.\n",
    "        output_path (str): Path to the output file (default: './output.tsv').\n",
    "        add_header (str): Header to add if the header does not exist in the input file (default: None).\n",
    "        replace_header (str): Header to replace the existing header (default: None).\n",
    "        filter_columns (str): Columns to filter from the header (default: None).\n",
    "        remove_sampleid (bool): Whether to remove the SampleID column (default: False).\n",
    "        combine_alleles (bool): Whether to combine allele columns into one (default: False).\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(input_path):\n",
    "        raise FileNotFoundError(f\"The input file {input_path} does not exist.\")\n",
    "    \n",
    "    df_check = core.DataFrame()\n",
    "    df_check.import_data(input_path, file_type='tsv')\n",
    "    \n",
    "    if check_if_mlst_empty(df_check):\n",
    "        with open(output_path, 'w') as f:\n",
    "            f.write('')\n",
    "        return\n",
    "\n",
    "    df = core.DataFrame()\n",
    "    df.import_data(input_path, file_type='tsv')\n",
    "\n",
    "    if combine_alleles:\n",
    "        #print 4th and further values of df.df.columns in a comma separated list\n",
    "        combine_alleles_string = ','.join(df.df.columns[3:])\n",
    "\n",
    "        #Replace 4th column with combined string\n",
    "        cols = list(df.df.columns)\n",
    "        cols[3] = combine_alleles_string\n",
    "        df.df.columns = cols\n",
    "\n",
    "        #Remove columns after 4th\n",
    "        df.df = df.df.iloc[:, :4]\n",
    "\n",
    "    if add_header:\n",
    "        header_list = add_header.split(\", \")\n",
    "        #Add more headers if not combining alleles\n",
    "        if not combine_alleles:            \n",
    "            header_list[3] = header_list[3] + \"1\"\n",
    "            for i in range(4, len(df.df.columns)):\n",
    "                header_list.append(header_list[3][:-1] + str(i-2))\n",
    "        df.df.loc[-1] = df.df.columns  # adding header as first row\n",
    "        df.df.index = df.df.index + 1  # shifting index\n",
    "        df.df = df.df.sort_index()  # sorting by index to move the header row to the top\n",
    "        df.df.columns = header_list  # setting new header\n",
    "\n",
    "    if replace_header:\n",
    "        df.rename_header(replace_header)\n",
    "\n",
    "    if filter_columns:\n",
    "        df.filter_columns(filter_columns)\n",
    "\n",
    "    if remove_sampleid:\n",
    "        # Remove the first column (SampleID) if it exists\n",
    "        if df.df.columns[0] == \"SampleID\":\n",
    "            df.df = df.df.iloc[:, 1:]\n",
    "\n",
    "    df.export_data(output_path, file_type='tsv')\n",
    "\n",
    "def check_if_mlst_empty(df):\n",
    "    if (df.df.columns[1] == \"-\"):\n",
    "        return(True)\n",
    "    else:\n",
    "        return(False)\n",
    "\n",
    "@call_parse\n",
    "def process_mlst_data_from_cli(\n",
    "    input_path:str,\n",
    "    output_path:str = './output.tsv',\n",
    "    add_header:str = None,\n",
    "    replace_header:str = None,\n",
    "    filter_columns:str = None,\n",
    "    remove_sampleid:bool = False,\n",
    "    combine_alleles:bool = False):\n",
    "    process_mlst_data(input_path, output_path, add_header, replace_header, filter_columns, remove_sampleid, combine_alleles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "# Example usage of the function\n",
    "#process_mlst_data( \n",
    "#    input_path='test_data/mlst_empty.tabular',\n",
    "#    input_path='test_data/mlst_rep_test.tsv',\n",
    "#    output_path='test_data/output.tsv',\n",
    "#    add_header=\"SampleID, Species, ST\",\n",
    "#    replace_header=None, \n",
    "#    filter_columns=\"SampleID, Species, ST\"\n",
    "#)\n",
    "#process_mlst_data(\n",
    "#        input_path='test_data/mlst_report.tabular',\n",
    "#        output_path='test_data/bifrost/parsed_mlst.tsv',\n",
    "#        replace_header=None, \n",
    "#        #filter_columns=\"SampleID, Species, ST\",\n",
    "#        remove_sampleid=True,\n",
    "#        combine_alleles=True,\n",
    "#        add_header=\"SampleID, Species, ST, Alleles\"\n",
    "#)\n",
    "\n",
    "#process_mlst_data(\n",
    "#        input_path='test_data/empty_file_test.txt',\n",
    "#        output_path='test_data/empty_file_output.txt',\n",
    "#        replace_header=None,\n",
    "#        remove_sampleid=True,\n",
    "#        add_header=\"SampleID, MLST_Species, MLST_ST, MLST_Alleles\",\n",
    "#        combine_alleles=True\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##################################################CODE_SEGMENT###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# This is included at the end to ensure when you run through your notebook the code is also transferred to the associated python package\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
