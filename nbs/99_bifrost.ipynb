{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |default_exp bifrost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "# See above? this hides these blocks, meaning these blocks aren't in the module and aren't in the documentation\n",
    "import nbdev\n",
    "from nbdev.showdoc import *  # ignore this Pylance warning in favor of following nbdev docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "# That export there, it makes sure this code goes into the module.\n",
    "\n",
    "# standard libs\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Common to template\n",
    "# add into settings.ini, requirements, package name is python-dotenv, for conda build ensure `conda config --add channels conda-forge`\n",
    "import dotenv  # for loading config from .env files, https://pypi.org/project/python-dotenv/\n",
    "import envyaml  # Allows to loads env vars into a yaml file, https://github.com/thesimj/envyaml\n",
    "import fastcore  # To add functionality related to nbdev development, https://github.com/fastai/fastcore/\n",
    "from fastcore import (\n",
    "    test,\n",
    ")\n",
    "from fastcore.script import (\n",
    "    call_parse,\n",
    ")  # for @call_parse, https://fastcore.fast.ai/script\n",
    "import json  # for nicely printing json and yaml\n",
    "from fastcore import test\n",
    "\n",
    "#!export\n",
    "from bifrost_bridge import core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "# This block should never be exported. It is to have python running in the project (and not the nbs) dir, and to initiate the package using pip.\n",
    "os.chdir(core.PROJECT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##################################################CODE_SEGMENT###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "from bifrost_bridge.mlst import process_mlst_data\n",
    "from bifrost_bridge.fastp import process_fastp_data\n",
    "from bifrost_bridge.quast import process_quast_data\n",
    "from bifrost_bridge.plasmidfinder import process_plasmidfinder_data\n",
    "from bifrost_bridge.amrfinderplus import process_amrfinderplus_data\n",
    "from bifrost_bridge.bracken import process_bracken_data\n",
    "from bifrost_bridge.pmlst import process_pmlst_data\n",
    "from bifrost_bridge.rmlst import process_rmlst_data\n",
    "import pandas as pd\n",
    "\n",
    "@call_parse\n",
    "def process_qc_data(\n",
    "    mlst_path:str = None,\n",
    "    fastp_path:str = None,\n",
    "    quast_path:str = None,\n",
    "    plasmidfinder_path:str = None,\n",
    "    bracken_path:str = None,\n",
    "    amrfinder_path:str = None,\n",
    "    pmlst_path:str = None,\n",
    "    rmlst_path:str = None,\n",
    "    combine_output:bool = True,\n",
    "    output_path:str = './output.tsv'):\n",
    "\n",
    "    \"\"\"\n",
    "    Command-line interface for processing QC data.\n",
    "\n",
    "    This function processes MLST, FASTP, QUAST, PlasmidFinder, and Bracken data files based on the provided command-line arguments.\n",
    "    It supports specifying input file paths for MLST, FASTP, QUAST, PlasmidFinder, and Bracken data, and outputs the processed data to specified paths.\n",
    "\n",
    "    Arguments:\n",
    "        mlst_path (str): Path to the MLST input file.\n",
    "        fastp_path (str): Path to the FASTP input file.\n",
    "        quast_path (str): Path to the QUAST input file.\n",
    "        plasmidfinder_path (str): Path to the PlasmidFinder input file.\n",
    "        bracken_path (str): Path to the Bracken input file.\n",
    "        amrfinder_path (str): Path to the AMRFinder input file.\n",
    "        pmlst_path (str): Path to the PMLST input file.\n",
    "        output_path (str): Path to the output file (default: './output.tsv').\n",
    "    \"\"\"\n",
    "    if mlst_path is not None:\n",
    "        if not os.path.exists(mlst_path):\n",
    "            raise FileNotFoundError(f\"File not found: {mlst_path}\")\n",
    "        process_mlst_data(\n",
    "        input_path=mlst_path, \n",
    "        output_path='parsed_mlst.tsv',\n",
    "        replace_header=None, \n",
    "        #filter_columns=\"SampleID, Species, ST\",\n",
    "        remove_sampleid=True,\n",
    "        add_header=\"SampleID, MLST_Species, MLST_ST, MLST_Allele\"\n",
    "        )\n",
    "\n",
    "    if fastp_path is not None:\n",
    "        if not os.path.exists(fastp_path):\n",
    "            raise FileNotFoundError(f\"File not found: {fastp_path}\")\n",
    "        process_fastp_data(\n",
    "            input_path=fastp_path, \n",
    "            output_path='parsed_fastp.tsv',\n",
    "            filter_columns=\"summary£before_filtering£total_reads, summary£before_filtering£read1_mean_length, summary£before_filtering£read2_mean_length, summary£after_filtering£total_reads, summary£after_filtering£read1_mean_length, summary£after_filtering£read2_mean_length, filtering_result£low_quality_reads, filtering_result£too_many_N_reads, filtering_result£too_short_reads, filtering_result£too_long_reads, duplication£rate, adapter_cutting£adapter_trimmed_reads, adapter_cutting£adapter_trimmed_bases, read1_before_filtering£total_cycles, read1_after_filtering£total_cycles, read2_before_filtering£total_cycles, read2_after_filtering£total_cycles\",\n",
    "            replace_header=\"fastp_Before_Filtering_Total_Reads,fastp_Before_Filtering_Read1_Mean_Length,fastp_Before_Filtering_Read2_Mean_Length,fastp_After_Filtering_Total_Reads,fastp_After_Filtering_Read1_Mean_Length,fastp_After_Filtering_Read2_Mean_Length,fastp_Low_Quality_Reads,fastp_Too_Many_N_Reads,fastp_Too_Short_Reads,fastp_Too_Long_Reads,fastp_Duplication_Rate,fastp_Adapter_Trimmed_Reads,fastp_Adapter_Trimmed_Bases,fastp_Read1_Before_Filtering_Total_Cycles,fastp_Read1_After_Filtering_Total_Cycles,fastp_Read2_Before_Filtering_Total_Cycles,fastp_Read2_After_Filtering_Total_Cycles\"\n",
    "        )\n",
    "\n",
    "    if quast_path is not None:\n",
    "        if not os.path.exists(quast_path):\n",
    "            raise FileNotFoundError(f\"File not found: {quast_path}\")\n",
    "        process_quast_data(\n",
    "            input_path=quast_path, \n",
    "            output_path='parsed_quast.tsv',\n",
    "            filter_columns='# contigs, Largest contig, Total length, GC (%), N50, N90, L50, L90',\n",
    "            replace_header=\"Quast_Contigs,Quast_Largest_Contig,Quast_Total_Length,Quast_GC_Pct,Quast_N50,Quast_N90,Quast_L50,Quast_L90\",\n",
    "            transpose=True\n",
    "        )\n",
    "    \n",
    "    if plasmidfinder_path is not None:\n",
    "        if not os.path.exists(plasmidfinder_path):\n",
    "            raise FileNotFoundError(f\"File not found: {plasmidfinder_path}\")\n",
    "        process_plasmidfinder_data(\n",
    "            input_path=plasmidfinder_path, \n",
    "            output_path='parsed_plasmidfinder.tsv',\n",
    "            filter_columns=\"Database,Plasmid,Identity,Query / Template length,Contig\",\n",
    "            replace_header=\"PFInder_Database,PFinder_Plasmid,PFinder_Identity,PFinder_Coverage,PFinder_Contig\",\n",
    "            convert_coverage=True,\n",
    "            filter_contig=True\n",
    "        )\n",
    "\n",
    "    if bracken_path is not None:\n",
    "        if not os.path.exists(bracken_path):\n",
    "            raise FileNotFoundError(f\"File not found: {bracken_path}\")\n",
    "        process_bracken_data(\n",
    "            input_path=bracken_path, \n",
    "            output_path='parsed_bracken.tsv',\n",
    "            replace_header=\"Bracken_Species,Bracken_Species_Pct,Bracken_Species1,Bracken_Species1_Pct,Bracken_Species2,Bracken_Species2_Pct,Bracken_Unclassified,Bracken_Unclassified_Pct\"\n",
    "        )\n",
    "\n",
    "    if amrfinder_path is not None:\n",
    "        if not os.path.exists(amrfinder_path):\n",
    "            raise FileNotFoundError(f\"File not found: {amrfinder_path}\")\n",
    "        process_amrfinderplus_data(\n",
    "            input_path=amrfinder_path, \n",
    "            output_path='parsed_amrfinder.tsv',\n",
    "            filter_columns=\"Contig id,Start,Stop,Strand,Gene symbol,Sequence name,Subclass,% Coverage of reference sequence,% Identity to reference sequence\",\n",
    "            replace_header=\"AMR_ContigID,AMR_Start,AMR_Stop,AMR_Strand,AMR_ElementSymbol,AMR_ElementName,AMR_Subclass,AMR_Coverage,AMR_Identity\"\n",
    "        )\n",
    "\n",
    "    if pmlst_path is not None:\n",
    "        if not os.path.exists(pmlst_path):\n",
    "            raise FileNotFoundError(f\"File not found: {pmlst_path}\")\n",
    "        process_pmlst_data(\n",
    "            input_path=pmlst_path, \n",
    "            output_path='parsed_pmlst.tsv',\n",
    "            replace_header=\"pMLST_plasmids,pMLST_IncF,pMLST_IncI1,pMLST_IncA/C,pMLST_IncHI1,pMLST_IncHI2,pMLST_IncN,pMLST_summary\"\n",
    "        )\n",
    "\n",
    "    if rmlst_path is not None:\n",
    "        if not os.path.exists(rmlst_path):\n",
    "            raise FileNotFoundError(f\"File not found: {rmlst_path}\")\n",
    "        process_rmlst_data(\n",
    "            input_path=rmlst_path, \n",
    "            output_path='parsed_rmlst.tsv',\n",
    "            filter_columns=\"taxon,rank,support\",\n",
    "            replace_header=\"rMLST_match,rMLST_rank,rMLST_support\"\n",
    "        )\n",
    "    \n",
    "    if combine_output:\n",
    "        # List of output files that were actually created\n",
    "        output_files = []\n",
    "        if mlst_path is not None:\n",
    "            if os.path.getsize('parsed_mlst.tsv') > 0:\n",
    "                output_files.append('parsed_mlst.tsv')\n",
    "        if fastp_path is not None:\n",
    "            output_files.append('parsed_fastp.tsv')\n",
    "        if quast_path is not None:\n",
    "            output_files.append('parsed_quast.tsv')\n",
    "        if plasmidfinder_path is not None:\n",
    "            output_files.append('parsed_plasmidfinder.tsv')\n",
    "        if amrfinder_path is not None:\n",
    "            output_files.append('parsed_amrfinder.tsv')\n",
    "        if bracken_path is not None:\n",
    "            output_files.append('parsed_bracken.tsv')\n",
    "        if pmlst_path is not None:\n",
    "            output_files.append('parsed_pmlst.tsv')\n",
    "        if rmlst_path is not None:\n",
    "            output_files.append('parsed_rmlst.tsv')\n",
    "\n",
    "        # Read and concatenate all output files\n",
    "        combined_df = pd.concat([pd.read_csv(file, sep='\\t') for file in output_files], axis=1)\n",
    "\n",
    "        # Save the combined dataframe to the specified output path\n",
    "        combined_df.to_csv(output_path, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# |hide\n",
    "# Example usage of the function\n",
    "process_qc_data(\n",
    "    mlst_path='test_data/mlst_report.tabular', \n",
    "    #mlst_path='test_data/mlst_empty.tabular',\n",
    "    fastp_path='test_data/TestSample2.json',\n",
    "    quast_path='test_data/quast.tsv',\n",
    "    plasmidfinder_path='test_data/plasmidfinder.tsv',\n",
    "    bracken_path='test_data/bracken_krakenreport.txt',\n",
    "    amrfinder_path='test_data/amrfinderbug.tsv',\n",
    "    pmlst_path='test_data/simple_output.tsv',\n",
    "    rmlst_path='test_data/rmlst.json',\n",
    "    combine_output = True,\n",
    "    output_path = 'test_data/bifrost/output.tsv'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##################################################CODE_SEGMENT###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# This is included at the end to ensure when you run through your notebook the code is also transferred to the associated python package\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
