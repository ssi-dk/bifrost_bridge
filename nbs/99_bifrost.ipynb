{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |default_exp bifrost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "# See above? this hides these blocks, meaning these blocks aren't in the module and aren't in the documentation\n",
    "import nbdev\n",
    "from nbdev.showdoc import *  # ignore this Pylance warning in favor of following nbdev docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "# That export there, it makes sure this code goes into the module.\n",
    "\n",
    "# standard libs\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Common to template\n",
    "# add into settings.ini, requirements, package name is python-dotenv, for conda build ensure `conda config --add channels conda-forge`\n",
    "import dotenv  # for loading config from .env files, https://pypi.org/project/python-dotenv/\n",
    "import envyaml  # Allows to loads env vars into a yaml file, https://github.com/thesimj/envyaml\n",
    "import fastcore  # To add functionality related to nbdev development, https://github.com/fastai/fastcore/\n",
    "from fastcore import (\n",
    "    test,\n",
    ")\n",
    "from fastcore.script import (\n",
    "    call_parse,\n",
    ")  # for @call_parse, https://fastcore.fast.ai/script\n",
    "import json  # for nicely printing json and yaml\n",
    "from fastcore import test\n",
    "\n",
    "#!export\n",
    "from bifrost_bridge import core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "# This block should never be exported. It is to have python running in the project (and not the nbs) dir, and to initiate the package using pip.\n",
    "os.chdir(core.PROJECT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##################################################CODE_SEGMENT###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "from bifrost_bridge.mlst import process_mlst_data\n",
    "from bifrost_bridge.fastp import process_fastp_data\n",
    "from bifrost_bridge.quast import process_quast_data\n",
    "from bifrost_bridge.plasmidfinder import process_plasmidfinder_data\n",
    "from bifrost_bridge.amrfinderplus import process_amrfinderplus_data\n",
    "from bifrost_bridge.bracken import process_bracken_data\n",
    "from bifrost_bridge.pmlst import process_pmlst_data\n",
    "from bifrost_bridge.rmlst import process_rmlst_data\n",
    "import pandas as pd\n",
    "\n",
    "@call_parse\n",
    "def process_qc_data(\n",
    "    mlst_path:str = None,\n",
    "    fastp_path:str = None,\n",
    "    quast_path:str = None,\n",
    "    plasmidfinder_path:str = None,\n",
    "    bracken_path:str = None,\n",
    "    amrfinder_path:str = None,\n",
    "    pmlst_path:str = None,\n",
    "    rmlst_path:str = None,\n",
    "    combine_output:bool = True,\n",
    "    output_path:str = './output.tsv'):\n",
    "\n",
    "    \"\"\"\n",
    "    Command-line interface for processing QC data.\n",
    "\n",
    "    This function processes MLST, FASTP, QUAST, PlasmidFinder, and Bracken data files based on the provided command-line arguments.\n",
    "    It supports specifying input file paths for MLST, FASTP, QUAST, PlasmidFinder, and Bracken data, and outputs the processed data to specified paths.\n",
    "\n",
    "    Arguments:\n",
    "        mlst_path (str): Path to the MLST input file.\n",
    "        fastp_path (str): Path to the FASTP input file.\n",
    "        quast_path (str): Path to the QUAST input file.\n",
    "        plasmidfinder_path (str): Path to the PlasmidFinder input file.\n",
    "        bracken_path (str): Path to the Bracken input file.\n",
    "        amrfinder_path (str): Path to the AMRFinder input file.\n",
    "        pmlst_path (str): Path to the PMLST input file.\n",
    "        output_path (str): Path to the output file (default: './output.tsv').\n",
    "    \"\"\"\n",
    "    if mlst_path is not None:\n",
    "        if not os.path.exists(mlst_path):\n",
    "            raise FileNotFoundError(f\"File not found: {mlst_path}\")\n",
    "        process_mlst_data(\n",
    "        input_path=mlst_path, \n",
    "        output_path='parsed_mlst.tsv',\n",
    "        replace_header=None, \n",
    "        filter_columns=\"SampleID, Species, ST\",\n",
    "        add_header=\"SampleID, Species, ST, Allele\"\n",
    "        )\n",
    "\n",
    "    if fastp_path is not None:\n",
    "        if not os.path.exists(fastp_path):\n",
    "            raise FileNotFoundError(f\"File not found: {fastp_path}\")\n",
    "        process_fastp_data(\n",
    "            input_path=fastp_path, \n",
    "            output_path='parsed_fastp.tsv',\n",
    "            filter_columns=\"summary£fastp_version, summary£sequencing, summary£before_filtering£total_reads\",\n",
    "            replace_header=\"fastp_version, sequencing, total_reads\"\n",
    "        )\n",
    "\n",
    "    if quast_path is not None:\n",
    "        if not os.path.exists(quast_path):\n",
    "            raise FileNotFoundError(f\"File not found: {quast_path}\")\n",
    "        process_quast_data(\n",
    "            input_path=quast_path, \n",
    "            output_path='parsed_quast.tsv',\n",
    "            filter_columns='Assembly,# contigs (>= 0 bp), N50',\n",
    "            transpose=True\n",
    "        )\n",
    "    \n",
    "    if plasmidfinder_path is not None:\n",
    "        if not os.path.exists(plasmidfinder_path):\n",
    "            raise FileNotFoundError(f\"File not found: {plasmidfinder_path}\")\n",
    "        process_plasmidfinder_data(\n",
    "            input_path=plasmidfinder_path, \n",
    "            output_path='parsed_plasmidfinder.tsv',\n",
    "        )\n",
    "\n",
    "    if bracken_path is not None:\n",
    "        if not os.path.exists(bracken_path):\n",
    "            raise FileNotFoundError(f\"File not found: {bracken_path}\")\n",
    "        process_bracken_data(\n",
    "            input_path=bracken_path, \n",
    "            output_path='parsed_bracken.tsv',\n",
    "        )\n",
    "\n",
    "    if amrfinder_path is not None:\n",
    "        if not os.path.exists(amrfinder_path):\n",
    "            raise FileNotFoundError(f\"File not found: {amrfinder_path}\")\n",
    "        process_amrfinderplus_data(\n",
    "            input_path=amrfinder_path, \n",
    "            output_path='parsed_amrfinder.tsv'\n",
    "        )\n",
    "\n",
    "    if pmlst_path is not None:\n",
    "        if not os.path.exists(pmlst_path):\n",
    "            raise FileNotFoundError(f\"File not found: {pmlst_path}\")\n",
    "        process_pmlst_data(\n",
    "            input_path=pmlst_path, \n",
    "            output_path='parsed_pmlst.tsv'\n",
    "        )\n",
    "\n",
    "    if rmlst_path is not None:\n",
    "        if not os.path.exists(rmlst_path):\n",
    "            raise FileNotFoundError(f\"File not found: {rmlst_path}\")\n",
    "        process_rmlst_data(\n",
    "            input_path=rmlst_path, \n",
    "            output_path='parsed_rmlst.tsv',\n",
    "            filter_columns=\"taxon,taxonomy,rank,support\",\n",
    "            replace_header=\"match,taxonomy,rank,percentage\"\n",
    "        )\n",
    "    \n",
    "    if combine_output:\n",
    "        # List of output files that were actually created\n",
    "        output_files = []\n",
    "        if mlst_path is not None:\n",
    "            if os.path.getsize('parsed_mlst.tsv') > 0:\n",
    "                output_files.append('parsed_mlst.tsv')\n",
    "        if fastp_path is not None:\n",
    "            output_files.append('parsed_fastp.tsv')\n",
    "        if quast_path is not None:\n",
    "            output_files.append('parsed_quast.tsv')\n",
    "        if plasmidfinder_path is not None:\n",
    "            output_files.append('parsed_plasmidfinder.tsv')\n",
    "        if amrfinder_path is not None:\n",
    "            output_files.append('parsed_amrfinder.tsv')\n",
    "        if bracken_path is not None:\n",
    "            output_files.append('parsed_bracken.tsv')\n",
    "        if pmlst_path is not None:\n",
    "            output_files.append('parsed_pmlst.tsv')\n",
    "        if rmlst_path is not None:\n",
    "            output_files.append('parsed_rmlst.tsv')\n",
    "\n",
    "        # Read and concatenate all output files\n",
    "        combined_df = pd.concat([pd.read_csv(file, sep='\\t') for file in output_files], axis=1)\n",
    "\n",
    "        # Save the combined dataframe to the specified output path\n",
    "        combined_df.to_csv(output_path, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# |hide\n",
    "# Example usage of the function\n",
    "#process_qc_data(\n",
    "#    mlst_path='test_data/mlst_report.tabular', \n",
    "#    #mlst_path='test_data/mlst_empty.tabular',\n",
    "#    fastp_path='test_data/TestSample2.json',\n",
    "#    quast_path='test_data/quast.tsv',\n",
    "#    plasmidfinder_path='test_data/plasmidfinder.tsv',\n",
    "#    bracken_path='test_data/bracken_krakenreport.txt',\n",
    "#    amrfinder_path='test_data/amrfinderplus_long_example.tsv',\n",
    "#    pmlst_path='test_data/simple_output.tsv',\n",
    "#    combine_output = True,\n",
    "#    output_path = 'test_data/bifrost/output.tsv'\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##################################################CODE_SEGMENT###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# This is included at the end to ensure when you run through your notebook the code is also transferred to the associated python package\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
