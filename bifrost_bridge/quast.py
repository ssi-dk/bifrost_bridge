# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/04_quast.ipynb.

# %% auto 0
__all__ = ['process_quast_data', 'process_quast_data_from_cli']

# %% ../nbs/04_quast.ipynb 2
# That export there, it makes sure this code goes into the module.

# standard libs
import os
import re

# Common to template
# add into settings.ini, requirements, package name is python-dotenv, for conda build ensure `conda config --add channels conda-forge`
import dotenv  # for loading config from .env files, https://pypi.org/project/python-dotenv/
import envyaml  # Allows to loads env vars into a yaml file, https://github.com/thesimj/envyaml
import fastcore  # To add functionality related to nbdev development, https://github.com/fastai/fastcore/
from fastcore import (
    test,
)
from fastcore.script import (
    call_parse,
)  # for @call_parse, https://fastcore.fast.ai/script
import json  # for nicely printing json and yaml
from fastcore import test

#!export
from . import core

# %% ../nbs/04_quast.ipynb 5
def process_quast_data(
    input_path: str,
    output_path: str = "./output.tsv",
    replace_header: str = None,
    filter_columns: str = None,
    transpose: bool = True,
):
    """
    Command-line interface for processing MLST data.

    This function sets up an argument parser to handle command-line arguments for processing quast data files.
    It supports specifying input and output file paths, replacing headers, filtering columns.

    Arguments:
        input_path (str): Path to the input file.
        output_path (str): Path to the output file (default: './output.tsv').
        replace_header (str): Header to replace the existing header (default: None).
        filter_columns (str): Columns to filter from the header (default: None).
    """

    df = core.DataFrame()
    df.import_data(input_path, file_type="csv", add_header="placeholder")

    # df.print_header()
    # df.show()

    if replace_header:
        df.rename_header(replace_header)

    if transpose:
        df_df = df.df
        df_df[["column_names", "values"]] = df_df["placeholder"].str.split(
            "\t", expand=True
        )
        df_df.drop("placeholder", axis=1, inplace=True)
        df_df = df_df.T
        df_df = df_df.rename(columns=df_df.loc["column_names"])
        df_df.drop("column_names", axis=0, inplace=True)
        # print(df_df, df_df.shape)
        df.df = df_df
        # df_df.columns = df_df['column_names']

    if filter_columns:
        df.filter_columns(filter_columns)

    # print(df.df)
    # print(type(df.df))

    df.export_data(output_path, file_type="tsv")


@call_parse
def process_quast_data_from_cli(
    input_path: str,
    output_path: str = "./output.tsv",
    replace_header: str = None,
    filter_columns: str = None,
    transpose: bool = True,
):
    process_quast_data(
        input_path, output_path, replace_header, filter_columns, transpose
    )
